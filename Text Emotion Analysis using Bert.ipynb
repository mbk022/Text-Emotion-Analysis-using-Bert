{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "349ceca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ktrain\n",
      "  Downloading ktrain-0.41.3.tar.gz (25.3 MB)\n",
      "     ---------------------------------------- 25.3/25.3 MB 4.5 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\mbk02\\anaconda3\\lib\\site-packages (from ktrain) (1.3.1)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\mbk02\\anaconda3\\lib\\site-packages (from ktrain) (3.5.2)\n",
      "Requirement already satisfied: pandas>=1.0.1 in c:\\users\\mbk02\\anaconda3\\lib\\site-packages (from ktrain) (2.1.1)\n",
      "Collecting fastprogress>=0.1.21\n",
      "  Downloading fastprogress-1.0.3-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\mbk02\\anaconda3\\lib\\site-packages (from ktrain) (2.28.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\mbk02\\anaconda3\\lib\\site-packages (from ktrain) (1.3.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\mbk02\\anaconda3\\lib\\site-packages (from ktrain) (21.3)\n",
      "Collecting langdetect\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "     -------------------------------------- 981.5/981.5 kB 4.8 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting jieba\n",
      "  Downloading jieba-0.42.1.tar.gz (19.2 MB)\n",
      "     ---------------------------------------- 19.2/19.2 MB 4.6 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: charset-normalizer in c:\\users\\mbk02\\anaconda3\\lib\\site-packages (from ktrain) (2.0.4)\n",
      "Requirement already satisfied: chardet in c:\\users\\mbk02\\anaconda3\\lib\\site-packages (from ktrain) (4.0.0)\n",
      "Collecting syntok>1.3.3\n",
      "  Downloading syntok-1.4.4-py3-none-any.whl (24 kB)\n",
      "Collecting tika\n",
      "  Downloading tika-2.6.0.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.41.2-py3-none-any.whl (9.1 MB)\n",
      "     ---------------------------------------- 9.1/9.1 MB 5.1 MB/s eta 0:00:00\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.0-cp39-cp39-win_amd64.whl (991 kB)\n",
      "     -------------------------------------- 991.5/991.5 kB 5.7 MB/s eta 0:00:00\n",
      "Collecting keras_bert>=0.86.0\n",
      "  Downloading keras-bert-0.89.0.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting whoosh\n",
      "  Downloading Whoosh-2.7.4-py2.py3-none-any.whl (468 kB)\n",
      "     -------------------------------------- 468.8/468.8 kB 5.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\mbk02\\anaconda3\\lib\\site-packages (from keras_bert>=0.86.0->ktrain) (1.24.4)\n",
      "Collecting keras-transformer==0.40.0\n",
      "  Downloading keras-transformer-0.40.0.tar.gz (9.7 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting keras-pos-embd==0.13.0\n",
      "  Downloading keras-pos-embd-0.13.0.tar.gz (5.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting keras-multi-head==0.29.0\n",
      "  Downloading keras-multi-head-0.29.0.tar.gz (13 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting keras-layer-normalization==0.16.0\n",
      "  Downloading keras-layer-normalization-0.16.0.tar.gz (3.9 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting keras-position-wise-feed-forward==0.8.0\n",
      "  Downloading keras-position-wise-feed-forward-0.8.0.tar.gz (4.1 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting keras-embed-sim==0.10.0\n",
      "  Downloading keras-embed-sim-0.10.0.tar.gz (3.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting keras-self-attention==0.51.0\n",
      "  Downloading keras-self-attention-0.51.0.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\mbk02\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->ktrain) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\mbk02\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->ktrain) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\mbk02\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->ktrain) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\mbk02\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->ktrain) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\mbk02\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->ktrain) (4.25.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\mbk02\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->ktrain) (10.0.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\mbk02\\anaconda3\\lib\\site-packages (from pandas>=1.0.1->ktrain) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mbk02\\anaconda3\\lib\\site-packages (from pandas>=1.0.1->ktrain) (2022.1)\n",
      "Requirement already satisfied: regex>2016 in c:\\users\\mbk02\\anaconda3\\lib\\site-packages (from syntok>1.3.3->ktrain) (2022.7.9)\n",
      "Requirement already satisfied: six in c:\\users\\mbk02\\anaconda3\\lib\\site-packages (from langdetect->ktrain) (1.16.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\mbk02\\anaconda3\\lib\\site-packages (from requests->ktrain) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mbk02\\anaconda3\\lib\\site-packages (from requests->ktrain) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mbk02\\anaconda3\\lib\\site-packages (from requests->ktrain) (2022.9.14)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\mbk02\\anaconda3\\lib\\site-packages (from scikit-learn->ktrain) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\mbk02\\anaconda3\\lib\\site-packages (from scikit-learn->ktrain) (1.9.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mbk02\\anaconda3\\lib\\site-packages (from tika->ktrain) (63.4.1)\n",
      "Collecting safetensors>=0.4.1\n",
      "  Downloading safetensors-0.4.3-cp39-none-win_amd64.whl (287 kB)\n",
      "     -------------------------------------- 287.9/287.9 kB 4.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\mbk02\\anaconda3\\lib\\site-packages (from transformers->ktrain) (6.0)\n",
      "Collecting tokenizers<0.20,>=0.19\n",
      "  Downloading tokenizers-0.19.1-cp39-none-win_amd64.whl (2.2 MB)\n",
      "     ---------------------------------------- 2.2/2.2 MB 4.2 MB/s eta 0:00:00\n",
      "Collecting huggingface-hub<1.0,>=0.23.0\n",
      "  Downloading huggingface_hub-0.23.2-py3-none-any.whl (401 kB)\n",
      "     -------------------------------------- 401.7/401.7 kB 5.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\mbk02\\anaconda3\\lib\\site-packages (from transformers->ktrain) (4.64.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\mbk02\\anaconda3\\lib\\site-packages (from transformers->ktrain) (3.6.0)\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Downloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
      "     -------------------------------------- 316.1/316.1 kB 3.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\mbk02\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.0->transformers->ktrain) (4.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\mbk02\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers->ktrain) (0.4.5)\n",
      "Building wheels for collected packages: ktrain, keras_bert, keras-transformer, keras-embed-sim, keras-layer-normalization, keras-multi-head, keras-pos-embd, keras-position-wise-feed-forward, keras-self-attention, jieba, langdetect, tika\n",
      "  Building wheel for ktrain (setup.py): started\n",
      "  Building wheel for ktrain (setup.py): finished with status 'done'\n",
      "  Created wheel for ktrain: filename=ktrain-0.41.3-py3-none-any.whl size=25316962 sha256=1d53baec9e5596d1c3e0e0579d55437548c70a9e0773a06319ce73f77f8e9a84\n",
      "  Stored in directory: c:\\users\\mbk02\\appdata\\local\\pip\\cache\\wheels\\0d\\8b\\d5\\9b7ae5b7a1a8f3a15afd3935ccef5fb80ab1afad42004dca19\n",
      "  Building wheel for keras_bert (setup.py): started\n",
      "  Building wheel for keras_bert (setup.py): finished with status 'done'\n",
      "  Created wheel for keras_bert: filename=keras_bert-0.89.0-py3-none-any.whl size=33501 sha256=c754060086641879a1706a0cab0a1ad68d3e9727bffb1fc22ed3d5c8259d0cbd\n",
      "  Stored in directory: c:\\users\\mbk02\\appdata\\local\\pip\\cache\\wheels\\4e\\26\\24\\14ecbc0166364db7f5500164b7d796263cf3cd10c57e892180\n",
      "  Building wheel for keras-transformer (setup.py): started\n",
      "  Building wheel for keras-transformer (setup.py): finished with status 'done'\n",
      "  Created wheel for keras-transformer: filename=keras_transformer-0.40.0-py3-none-any.whl size=12287 sha256=0d8ee1a49d819ae5357603049815717eb2abf10db7901e9ce7605e6ce49db01d\n",
      "  Stored in directory: c:\\users\\mbk02\\appdata\\local\\pip\\cache\\wheels\\5e\\d6\\d1\\c588c3b2b112c8f1173934995836ab2f2de8323cce99fa998f\n",
      "  Building wheel for keras-embed-sim (setup.py): started\n",
      "  Building wheel for keras-embed-sim (setup.py): finished with status 'done'\n",
      "  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.10.0-py3-none-any.whl size=3945 sha256=75005070075ecf479437e90087dc0726fa36ecfb488c5dc3fd3f343a704c10f7\n",
      "  Stored in directory: c:\\users\\mbk02\\appdata\\local\\pip\\cache\\wheels\\cb\\25\\02\\4bb438785ef9c10d07f6b3519f080b38917153fdac3108d738\n",
      "  Building wheel for keras-layer-normalization (setup.py): started\n",
      "  Building wheel for keras-layer-normalization (setup.py): finished with status 'done'\n",
      "  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.16.0-py3-none-any.whl size=4655 sha256=0ecf0a4de9c52904e755a513863cfc5b74d15fb32918a9d2599e2f07af5e07fc\n",
      "  Stored in directory: c:\\users\\mbk02\\appdata\\local\\pip\\cache\\wheels\\c1\\df\\15\\a88cdf68ce687574649f65063a743123e1bee79932b6eea3b6\n",
      "  Building wheel for keras-multi-head (setup.py): started\n",
      "  Building wheel for keras-multi-head (setup.py): finished with status 'done'\n",
      "  Created wheel for keras-multi-head: filename=keras_multi_head-0.29.0-py3-none-any.whl size=14979 sha256=e88155b24ee1584069f22911d2a700a6cbf1f67a17850e95f69969a0207ce439\n",
      "  Stored in directory: c:\\users\\mbk02\\appdata\\local\\pip\\cache\\wheels\\b3\\85\\50\\f232cac81ed1eb4dc20db31a9d1f4a8a1a8c696d4d27bff442\n",
      "  Building wheel for keras-pos-embd (setup.py): started\n",
      "  Building wheel for keras-pos-embd (setup.py): finished with status 'done'\n",
      "  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.13.0-py3-none-any.whl size=6946 sha256=d6b1f6eee92b9ef6b6e5c6357e4ae82c5b89fe1dd3199605adb980ab22760b80\n",
      "  Stored in directory: c:\\users\\mbk02\\appdata\\local\\pip\\cache\\wheels\\f5\\8c\\9a\\917bf72d493e084ca1706a02679185789c2715f50770d8c987\n",
      "  Building wheel for keras-position-wise-feed-forward (setup.py): started\n",
      "  Building wheel for keras-position-wise-feed-forward (setup.py): finished with status 'done'\n",
      "  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.8.0-py3-none-any.whl size=4969 sha256=ddb1addb4c236cd03a765fcfdfc70ae147c270d4ac1b32e29a52e9e06d477a65\n",
      "  Stored in directory: c:\\users\\mbk02\\appdata\\local\\pip\\cache\\wheels\\20\\36\\25\\efb605ab1742a179274a6f7cb113da1c6758f45e212b59bb4d\n",
      "  Building wheel for keras-self-attention (setup.py): started\n",
      "  Building wheel for keras-self-attention (setup.py): finished with status 'done'\n",
      "  Created wheel for keras-self-attention: filename=keras_self_attention-0.51.0-py3-none-any.whl size=18895 sha256=2c2abcf4756db31ab42524cdd002cf79fff2da285caffc5665879a2ac2a27d53\n",
      "  Stored in directory: c:\\users\\mbk02\\appdata\\local\\pip\\cache\\wheels\\78\\c1\\84\\b83a2fd6f1d63e136cba74bac4126bee3b8705eef6486635fd\n",
      "  Building wheel for jieba (setup.py): started\n",
      "  Building wheel for jieba (setup.py): finished with status 'done'\n",
      "  Created wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314459 sha256=6567fd2621db01d8b18c9d0344191b4ea91be578aa96c5e613eae9cd9be14591\n",
      "  Stored in directory: c:\\users\\mbk02\\appdata\\local\\pip\\cache\\wheels\\7d\\74\\cf\\08c94db4b784e2c1ef675a600b7b5b281fd25240dcb954ee7e\n",
      "  Building wheel for langdetect (setup.py): started\n",
      "  Building wheel for langdetect (setup.py): finished with status 'done'\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993225 sha256=5c72777aae2ff68a5d6215abc100865959fd76ddee5d687bde0aaa9dd17e22d3\n",
      "  Stored in directory: c:\\users\\mbk02\\appdata\\local\\pip\\cache\\wheels\\d1\\c1\\d9\\7e068de779d863bc8f8fc9467d85e25cfe47fa5051fff1a1bb\n",
      "  Building wheel for tika (setup.py): started\n",
      "  Building wheel for tika (setup.py): finished with status 'done'\n",
      "  Created wheel for tika: filename=tika-2.6.0-py3-none-any.whl size=32624 sha256=532a02be32c8515fa0d646d9a430ef8e800f9a3a97dabfc0c64d6b4d4d27d9e7\n",
      "  Stored in directory: c:\\users\\mbk02\\appdata\\local\\pip\\cache\\wheels\\13\\56\\18\\e752060632d32c39c9c4545e756dad281f8504dafcfac02b95\n",
      "Successfully built ktrain keras_bert keras-transformer keras-embed-sim keras-layer-normalization keras-multi-head keras-pos-embd keras-position-wise-feed-forward keras-self-attention jieba langdetect tika\n",
      "Installing collected packages: whoosh, sentencepiece, jieba, syntok, safetensors, langdetect, keras-self-attention, keras-position-wise-feed-forward, keras-pos-embd, keras-layer-normalization, keras-embed-sim, fsspec, fastprogress, tika, keras-multi-head, huggingface-hub, tokenizers, keras-transformer, transformers, keras_bert, ktrain\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2022.7.1\n",
      "    Uninstalling fsspec-2022.7.1:\n",
      "      Successfully uninstalled fsspec-2022.7.1\n",
      "Successfully installed fastprogress-1.0.3 fsspec-2024.5.0 huggingface-hub-0.23.2 jieba-0.42.1 keras-embed-sim-0.10.0 keras-layer-normalization-0.16.0 keras-multi-head-0.29.0 keras-pos-embd-0.13.0 keras-position-wise-feed-forward-0.8.0 keras-self-attention-0.51.0 keras-transformer-0.40.0 keras_bert-0.89.0 ktrain-0.41.3 langdetect-1.0.9 safetensors-0.4.3 sentencepiece-0.2.0 syntok-1.4.4 tika-2.6.0 tokenizers-0.19.1 transformers-4.41.2 whoosh-2.7.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ktrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cf897ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import ktrain\n",
    "from ktrain import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03a4eb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(r\"C:\\Users\\mbk02\\Documents\\Projects\\nlp-text-emotion-master\\data\\data_train.csv\", encoding='utf-8')\n",
    "data_test = pd.read_csv(r\"C:\\Users\\mbk02\\Documents\\Projects\\nlp-text-emotion-master\\data\\data_test.csv\", encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b87c991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>There are tons of other paintings that I thin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Yet the dog had grown old and less capable , a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fear</td>\n",
       "      <td>When I get into the tube or the train without ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fear</td>\n",
       "      <td>This last may be a source of considerable disq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anger</td>\n",
       "      <td>She disliked the intimacy he showed towards so...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Emotion                                               Text\n",
       "0  neutral   There are tons of other paintings that I thin...\n",
       "1  sadness  Yet the dog had grown old and less capable , a...\n",
       "2     fear  When I get into the tube or the train without ...\n",
       "3     fear  This last may be a source of considerable disq...\n",
       "4    anger  She disliked the intimacy he showed towards so..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "305180b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_train.Text.tolist()\n",
    "X_test = data_test.Text.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e316b9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = data_train.Emotion.tolist()\n",
    "y_test = data_test.Emotion.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5eadfd64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of training set: 7934\n",
      "size of validation set: 3393\n",
      "Emotion\n",
      "joy        2326\n",
      "sadness    2317\n",
      "anger      2259\n",
      "neutral    2254\n",
      "fear       2171\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>There are tons of other paintings that I thin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Yet the dog had grown old and less capable , a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fear</td>\n",
       "      <td>When I get into the tube or the train without ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fear</td>\n",
       "      <td>This last may be a source of considerable disq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anger</td>\n",
       "      <td>She disliked the intimacy he showed towards so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sadness</td>\n",
       "      <td>When my family heard that my Mother's cousin w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>joy</td>\n",
       "      <td>Finding out I am chosen to collect norms for C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>anger</td>\n",
       "      <td>A spokesperson said : ` Glen is furious that t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Yes .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sadness</td>\n",
       "      <td>When I see people with burns I feel sad, actua...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Emotion                                               Text\n",
       "0  neutral   There are tons of other paintings that I thin...\n",
       "1  sadness  Yet the dog had grown old and less capable , a...\n",
       "2     fear  When I get into the tube or the train without ...\n",
       "3     fear  This last may be a source of considerable disq...\n",
       "4    anger  She disliked the intimacy he showed towards so...\n",
       "5  sadness  When my family heard that my Mother's cousin w...\n",
       "6      joy  Finding out I am chosen to collect norms for C...\n",
       "7    anger  A spokesperson said : ` Glen is furious that t...\n",
       "8  neutral                                             Yes . \n",
       "9  sadness  When I see people with burns I feel sad, actua..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data_train._append(data_test, ignore_index=True)\n",
    "\n",
    "class_names = ['joy', 'sadness', 'fear', 'anger', 'neutral']\n",
    "\n",
    "print('size of training set: %s' % (len(data_train['Text'])))\n",
    "print('size of validation set: %s' % (len(data_test['Text'])))\n",
    "print(data.Emotion.value_counts())\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39d12b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = {\n",
    "    'joy': 0,\n",
    "    'sadness': 1,\n",
    "    'fear': 2,\n",
    "    'anger': 3,\n",
    "    'neutral': 4\n",
    "}\n",
    "\n",
    "# Integer values for each class\n",
    "y_train = [encoding[x] for x in y_train]\n",
    "y_test = [encoding[x] for x in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b5fe615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading pretrained BERT model (uncased_L-12_H-768_A-12.zip)...\n",
      "[██████████████████████████████████████████████████]\n",
      "extracting pretrained BERT model...\n",
      "done.\n",
      "\n",
      "cleanup downloaded zip...\n",
      "done.\n",
      "\n",
      "preprocessing train...\n",
      "language: en\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "done."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "preprocessing test...\n",
      "language: en\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "done."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task: text classification\n"
     ]
    }
   ],
   "source": [
    "(x_train,  y_train), (x_test, y_test), preproc = text.texts_from_array(x_train=X_train, y_train=y_train,\n",
    "                                                                       x_test=X_test, y_test=y_test,\n",
    "                                                                       class_names=class_names,\n",
    "                                                                       preprocess_mode='bert',\n",
    "                                                                       maxlen=350, \n",
    "                                                                       max_features=35000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7baa4e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "maxlen is 350\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "model = text.text_classifier('bert', train_data=(x_train,y_train), preproc=preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6672edb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = ktrain.get_learner(model, train_data=(x_train, y_train), \n",
    "                             val_data=(x_test, y_test),\n",
    "                             batch_size=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "41fa1356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "begin training using onecycle policy with max lr of 2e-05...\n",
      "Epoch 1/2\n",
      "1323/1323 [==============================] - 10757s 8s/step - loss: 0.8479 - accuracy: 0.6823 - val_loss: 0.5571 - val_accuracy: 0.8052\n",
      "Epoch 2/2\n",
      "1323/1323 [==============================] - 10342s 8s/step - loss: 0.3850 - accuracy: 0.8717 - val_loss: 0.5008 - val_accuracy: 0.8246\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x169147bb370>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.fit_onecycle(2e-5,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e76ffae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 1629s 15s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         joy       0.85      0.86      0.85       707\n",
      "     sadness       0.80      0.82      0.81       676\n",
      "        fear       0.86      0.85      0.86       679\n",
      "       anger       0.79      0.78      0.79       693\n",
      "     neutral       0.82      0.81      0.81       638\n",
      "\n",
      "    accuracy                           0.82      3393\n",
      "   macro avg       0.82      0.82      0.82      3393\n",
      "weighted avg       0.82      0.82      0.82      3393\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[607,  16,  16,  13,  55],\n",
       "       [ 14, 556,  32,  55,  19],\n",
       "       [ 17,  30, 578,  41,  13],\n",
       "       [ 25,  64,  33, 541,  30],\n",
       "       [ 52,  27,  10,  33, 516]], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.validate(val_data=(x_test, y_test), class_names=class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f811c7fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['joy', 'sadness', 'fear', 'anger', 'neutral']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor = ktrain.get_predictor(learner.model, preproc)\n",
    "predictor.get_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "793a7cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: neutral (0.34)\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "message = 'Awesome sauce'\n",
    "\n",
    "start_time = time.time() \n",
    "prediction = predictor.predict(message)\n",
    "\n",
    "print('predicted: {} ({:.2f})'.format(prediction, (time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f1aae6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "93cb3b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's save the predictor for later use\n",
    "predictor.save(r\"C:\\Users\\mbk02\\Documents\\11 Projects\\nlp-text-emotion-master\\models\\bert1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
